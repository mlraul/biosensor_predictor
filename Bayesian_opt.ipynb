{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian_opt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0zVuwmZYeihDP2pFEsrtC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlraul/biosensor_predictor/blob/main/Bayesian_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Net training whit K-Fold Cross Validation and Hypermarameter Optimization\n",
        "In this code, the net will be validated using the K-Fold CV method over severall trainings where hyperparameter optimization will be performed\n",
        "\n",
        "Note: using this notebook with Google Colab may exceed the computing time limit in the free version. It can be run locally through other notebooks such as Jupyter."
      ],
      "metadata": {
        "id": "0i8r8XxXFf_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import LSTM, Dense, Activation, Dropout, Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras import metrics\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#pip install git+https://github.com/fmfn/BayesianOptimization\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "metadata": {
        "id": "PXzRM87aFhnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading inputs\n",
        "\n",
        "- fp_m is a matrix where each row contains the fingerprint of a molecule. Each fingerprint is written in two successive rows.\n",
        "- aa_m is a 3-Dimensional array where each matrix represents the amino acids of the Transcription Factor (TF)."
      ],
      "metadata": {
        "id": "uYmzTnvYFqvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "aeENOOjLFriV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id':\"1EeFJCysQ6Ts0ebDkxMuohrRTYo4T0GDI\"})\n",
        "downloaded.GetContentFile('aa_neg_no_motifs_matrix.npy')\n",
        "aa_m = np.load('aa_neg_no_motifs_matrix.npy')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1co-dTn5YYPiXKgYTFJ6-wi2wGVoHXF7G\"})\n",
        "downloaded.GetContentFile('fingerprints_v3_matrix.npy')\n",
        "fp_m = np.load('fingerprints_v3_matrix.npy')"
      ],
      "metadata": {
        "id": "R4QamRlSFwaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the labels\n",
        "In our current input, every amino acids sequence is given twice:\n",
        "\n",
        "- The first one is associated to the fingerprint which represents the molecule with higher affinity with this TF.\n",
        "-The second one is associated to a random fingerprint to which the affinity is lower.\n",
        "\n",
        "With this idea in mind, the labels set consists on a repeated sequence of 1 and 0 (with 1 meaning affinity between the TF and the molecule, and 0 the opposite)."
      ],
      "metadata": {
        "id": "1gxY4HYVF3cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lbl = np.ones(len(fp_m))\n",
        "\n",
        "for i in range(1, len(lbl), 2):\n",
        "    lbl[i] = 0"
      ],
      "metadata": {
        "id": "-vMc1jnnF5j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Splitting the data\n",
        "Here two data subsets will be created:\n",
        "\n",
        "- The train data, which will be used to train the net. This will be splitted again in different folds when using the K-F CV.\n",
        "- The test data, which will be used to evaluate it."
      ],
      "metadata": {
        "id": "vZEGxV0SF6Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aa_train, aa_test, fp_train, fp_test, lbl_train, lbl_test = train_test_split(aa_m, fp_m, lbl, test_size = 0.20)"
      ],
      "metadata": {
        "id": "5eHZa0SkF991"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Black-box function\n",
        "Here the function to be optimized, it is to say, the loss function of the model, will be created.\n",
        "Several steps must be taken, as the loss value will be obtained by CV.\n",
        "\n",
        "**1- Model configuration.** Here different parameters of the net architecture will be defined.\n",
        "\n",
        "**2- K-Fold definition.** It defines de K-Fold Cross Validator.\n",
        "\n",
        "**3- Creating the net architecture.** It has two branches:\n",
        "- One for the amino acids and motifs matrixes. Here a LSTM layer is used, as the inputs are actually sequences.\n",
        "- Other for the molecules fingerprints. By the moment, a Dense layer is used here.\n",
        "\n",
        "Then, these two branches are concatenated. The current architecture finishes with a Dense layer as output.\n",
        "\n",
        "**4- K-F CV model evaluation.** Here the CV evaluation will be performed. \n",
        "\n",
        "**5- Average scores.** Here the score for each fold will be displayed, as well as the average of all scores. \n",
        "This result will be used to evaluate how well the model is performing."
      ],
      "metadata": {
        "id": "Uyp8FW6cF_if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def black_box_function(batch_size, num_epochs, learn_rate):\n",
        "    batch_size = round(batch_size)\n",
        "    num_epochs = round(num_epochs)\n",
        "    learn_rate = round(learn_rate)\n",
        "    learn_rate = learn_rate/100000\n",
        "\n",
        "\n",
        "    # 1- MODEL CONFIGURATION\n",
        "    # Input layers shape\n",
        "    i1_shape = np.shape(aa_m)[1:]\n",
        "    i2_shape = np.shape(fp_m)[1]\n",
        "\n",
        "    # Model parameters\n",
        "    loss_function = 'binary_crossentropy'\n",
        "    opt = Adam(learning_rate=learn_rate)\n",
        "    metrics = ['accuracy']\n",
        "\n",
        "    num_folds = 5\n",
        "\n",
        "    lstm_units = 90\n",
        "    dense_units = 70\n",
        "    densefp_units = 70\n",
        "\n",
        "    verbosity = 0\n",
        "    \n",
        "    # 2- K-FOLD DEFINITION\n",
        "    kfold = KFold(n_splits = num_folds)\n",
        "    \n",
        "    # 3- CREATING THE NET ARCHITECTURE \n",
        "\n",
        "    # Branch for sequences matrixes. A LSTM layer is used\n",
        "    input1 = Input(shape = i1_shape)\n",
        "    i11 = LSTM(lstm_units, activation='relu', recurrent_activation='sigmoid',\n",
        "              dropout=0.2, recurrent_dropout=0.01)(input1)\n",
        "\n",
        "    # Branch for fingerprints\n",
        "    input2 = Input(shape = i2_shape)\n",
        "    i21 = Dense(densefp_units, activation='relu')(input2)\n",
        "\n",
        "    # Joint of branches\n",
        "    concat = Concatenate()([i11, i21])\n",
        "\n",
        "    # Other layers TEST (DROPOUTS)\n",
        "    dense1 = Dense(dense_units, activation='relu')(concat)\n",
        "\n",
        "    # Output layer\n",
        "    out = Dense(1)(dense1)\n",
        "\n",
        "    # Creation and compilation of the model\n",
        "    model = Model(inputs = [input1, input2], outputs = out)\n",
        "    model.compile(loss = loss_function, optimizer = opt, metrics = metrics)\n",
        "    #print(model.summary())\n",
        "\n",
        "    # 4- K-F CV MODEL EVALUATION\n",
        "    \n",
        "    # Defining the per-fold score lists\n",
        "    acc_per_fold = []\n",
        "    loss_per_fold = []\n",
        "\n",
        "    fold_num = 1\n",
        "\n",
        "    # Saving the initial model weights\n",
        "    Wsave = model.get_weights()\n",
        "        \n",
        "    for train, val in kfold.split(aa_train, fp_train, lbl_train):\n",
        "\n",
        "        model.set_weights(Wsave)\n",
        "        \n",
        "        # Generate a print\n",
        "        print('------------------------------------------------------------------')\n",
        "        print(f'Training for fold {fold_num} ...')\n",
        "        \n",
        "        \n",
        "        history = model.fit([aa_train[train], fp_train[train]], lbl_train[train],\n",
        "                            validation_data=([aa_train[val], fp_train[val]], lbl_train[val]),\n",
        "                            batch_size = batch_size, \n",
        "                            epochs = num_epochs, \n",
        "                            verbose = verbosity)\n",
        "\n",
        "        fold_loss = history.history['val_loss'][-1]\n",
        "        fold_accuracy = history.history['val_accuracy'][-1] * 100\n",
        "        print(f'Score for fold {fold_num}: {list(history.history.keys())[2]} of {fold_loss}; {list(history.history.keys())[3]} of {fold_accuracy} %')\n",
        "\n",
        "        acc_per_fold.append(fold_accuracy)\n",
        "        loss_per_fold.append(fold_loss)\n",
        "        \n",
        "        # Increasing fold number\n",
        "        fold_num = fold_num + 1\n",
        "        \n",
        "    # 5- AVERAGE SCORES\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Score per fold')\n",
        "    for i in range(0, len(acc_per_fold)):\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} %')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Average scores for all folds:')\n",
        "    print(f'> Accuracy: {np.mean(acc_per_fold)} % (+- {np.std(acc_per_fold)} %)')\n",
        "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    \n",
        "    final_acc = np.mean(acc_per_fold)\n",
        "    \n",
        "    return final_acc"
      ],
      "metadata": {
        "id": "zoU7GX-hHHYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bayesian optimization\n",
        "The bounds for the hyperparameters and the optimizer are defined. Then, the optimization is performed"
      ],
      "metadata": {
        "id": "CipZPO8eIdyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bounded region of hyperparameter space\n",
        "pbounds = {'batch_size': (5, 100), 'num_epochs': (1, 100), 'learn_rate': (1, 10000)}\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f = black_box_function,\n",
        "    pbounds = pbounds,\n",
        "    random_state = 1)\n",
        "\n",
        "optimizer.maximize(\n",
        "    init_points=5,\n",
        "    n_iter=25)"
      ],
      "metadata": {
        "id": "EbInXx71IoGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, res in enumerate(optimizer.res):\n",
        "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
      ],
      "metadata": {
        "id": "E-NsSUq0I3cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters\n",
        "print(optimizer.max)"
      ],
      "metadata": {
        "id": "KiUE9zooI4gs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}